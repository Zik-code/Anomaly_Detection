
### 一、项目简介
通过深度学习模型对时序数据（如传感器指标、系统日志、业务指标等）进行建模，学习正常模式的特征，再通过“重构误差”或“预测误差”识别偏离正常模式的异常数据，最终实现对时序数据中异常片段的自动检测。


### 二、核心模块与流程拆解

#### 1. 数据层：加载与预处理
- **数据来源**：通过 `load_dataset(args.dataset)` 加载数据集，包含训练集（`train_loader`）、测试集（`test_loader`）和异常标签（`labels`）。原始数据存储在 `data` 文件夹，预处理后的数据（如清洗、归一化、时间对齐）存储在 `processed_data` 文件夹（通过 `preprocess.py` 处理，未展示具体逻辑）。
- **数据格式**：时序数据的基本形状为 `[时间步, 特征数]`，即每个时间步包含多个特征（如多传感器数据）。
- **窗口化处理**：  
  时序模型通常需要输入“滑动窗口”（包含连续多个时间步的片段）以捕捉时间依赖关系。`convert_to_windows` 函数实现这一转换：  
  - 窗口大小由模型的 `n_window` 属性定义（不同模型可配置不同窗口大小）。  
  - 对前 `w_size` 个时间步，用首元素填充缺失部分（避免窗口大小不足）。  
  - 对 `TranAD` 或 `Attention` 模型，窗口保持三维形状 `[窗口数, 窗口大小, 特征数]`；其他模型展平为一维特征 `[窗口数, 窗口大小×特征数]`。  


#### 2. 模型层：多种深度学习模型支持
项目集成了多种主流时序异常检测模型（定义在 `src/models.py`），核心思路是**通过模型重构或预测正常数据，异常数据的重构/预测误差会显著更大**。从 `main.py` 的 `backprop` 函数可看出支持的模型包括：

| 模型类型       | 核心逻辑                                                                 | 损失函数特点                                                                 |
|----------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| LSTM_AD（基础） | 基于LSTM的自编码器，通过LSTM编码时序特征，再解码重构输入                  | 均方误差（MSE），直接衡量重构误差                                             |
| TranAD         | 基于Transformer的异常检测模型，捕捉长时序依赖，输出双预测结果（动态加权） | MSE，对两个预测结果用动态权重（随训练轮次变化）组合损失                       |
| OmniAnomaly    | 变分自编码器（VAE）变体，引入KL散度正则化                                 | MSE（重构损失）+ β×KL散度（正则化，避免过拟合）                              |
| USAD           | 双自编码器模型，两个自编码器相互约束                                      | 两个自编码器的损失组合（带动态权重，随训练轮次调整）                           |
| GAN类模型      | 生成器重构数据，判别器区分真实/重构数据                                  | 生成器：MSE（重构损失）+ BCELoss（欺骗判别器）；判别器：BCELoss（区分真假） |
| 其他模型（如GDN、MTAD_GAT） | 图神经网络或注意力机制模型，捕捉特征间依赖关系                            | 基础MSE损失                                                                 |


#### 3. 训练与推理流程
核心通过 `backprop` 函数实现，支持“训练模式”和“测试模式”切换：

- **训练模式（training=True）**：  
  - 输入：窗口化的训练数据、模型、优化器（AdamW，带权重衰减防过拟合）、学习率调度器（StepLR，每5轮衰减为0.9倍）。  
  - 过程：根据模型类型计算损失（如MSE、KL散度、BCELoss等），通过反向传播更新模型参数，记录损失和学习率。  
  - 输出：本轮平均损失和当前学习率，用于监控训练过程。

- **测试模式（training=False）**：  
  - 输入：窗口化的测试数据、训练好的模型。  
  - 过程：关闭梯度计算，模型输出预测/重构结果，计算每个样本的损失（保留原始形状，不平均）。  
  - 输出：损失数组（用于判断异常）和预测结果（用于可视化对比）。  


#### 4. 模型保存与加载
- **保存（save_model）**：将模型参数、优化器状态、调度器状态、训练轮次、损失记录保存到 `checkpoints/模型名_数据集名/` 路径，方便中断后继续训练或直接用于测试。  
- **加载（load_model）**：根据模型名动态加载 `src.models` 中的模型类，若存在预训练模型则加载参数，否则初始化新模型（支持 `retrain` 参数控制是否重新训练）。  


#### 5. 异常判定
结合 `src.pot.py` 中的 `objFun` 函数，推测流程为：  
- 测试阶段计算所有样本的损失（重构/预测误差）。  
- 用 POT（Peak Over Threshold，峰值超过阈值）算法（通过 `src.pot` 实现）确定“正常损失阈值”（基于训练集正常数据的损失分布）。  
- 损失超过阈值的样本被标记为异常，与真实标签（`labels`）对比计算评估指标（如精确率、召回率，可能在 `src.utils` 中实现）。  

