
### 一、项目简介
这是一个集成了几个深度学习方法对时序数据进行异常检测的项目，参考了TranAD和DTAAD实验代码。

### 二、运行项目
安装python以及pytorch 

项目需要python 3.7以上的版本。 
请执行以下命令安装pytorch
```python
pip install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html
```
请执行以下命令安装所需库 

```python
pip install -r requirements.txt
```
所需数据集已经经过预处理并放置在processed_data文件夹下。
要在数据集上运行模型复现结果，请执行以下命令：
```python
python main.py --model <model> --dataset <dataset> # 加载预训练模型进行训练
```
```python
python main.py --model <model> --dataset <dataset> --retrain # 重新训练模型
```
其中，模型可以是 'TranAD'、'OmniAnomaly'、'DTAAD' 中的任意一个，数据集可以是 'SMAP'、'SMD'、 'NAB' 中的任意一个。

### 三、项目构建思路
核心模块由三个文件构成：  
- `models.py`：包含多个核心深度学习模型的定义，是算法实现的基础。  
- `backprop.py`：采用“基类+子类”的策略模式设计，基类定义训练和测试的通用接口，各模型子类继承后实现自身特有的训练与测试逻辑。  
- `main.py`：程序入口，统筹模型加载、数据处理、训练测试流程及结果评估的完整执行逻辑。

辅助模块包括：  
- `Tranutils.py`：存放TranAD、DTAAD等模型所需的Transformer组件及其他专属架构实现。  
- `utils.py`：提供通用工具函数支持。  
- `plotting.py`：负责可视化功能，生成训练曲线、预测结果等图表。
  
评估相关模块： 
- `pot.py`封装异常检测的核心评估指标计算逻辑，其中用到的SPOT算法独立存放在`spot.py`中。
### 四、核心模块与流程

#### 1. 数据层：加载与预处理
- **数据来源**：通过 `load_dataset(args.dataset)` 加载数据集，包含训练集（`train_loader`）、测试集（`test_loader`）和异常标签（`labels`）。原始数据存储在 `data` 文件夹，预处理后的数据存储在 `processed_data` 文件夹。
    - 详细的数据加载流程（SMD）：
      加载数据集，每台机器数据单独训练，根据命令行传递的数据集名称统一加载训练集测试集标签集到一个loader中,后续再从loader中加载train_loader和test_loader。如对于第一台机器，加载machine-1-1-train.npy,machine-1-1.test.npy,machine-1-1-labels到一个数据加载器loader中。loader[0],loader[1],loader[2]就分别对应machine-1-1-train.npy,machine-1-1.test.npy,machine-1-1-labels。这里指定了batch_size为一个.npy文件的所有数据，对SMD数据集而言，就是每次加载一个机器的全部测量数据。
- **窗口化处理（重点）**：
  对于需要经过窗口化处理的数据作为输入的模型（包含连续多个时间步的片段）以捕捉时间依赖关系。
  
  以TranAD为例，在SMD数据集的machine-1-1（28479×38）上进行测试和训练，设置窗口大小为10，每次一个窗口内的数据为（10×38），滑动窗口逻辑是 “以当前索引 i 为终点，向前截取 w_size 个时间步”。（这种设计确保了即使到最后几个时间步，窗口大小始终是 w_size（10），只有前 w_size 个时间步（i < 10）需要填充）。
  `convert_to_windows` 函数实现窗口化处理：  
  - 窗口大小由模型的 `n_window` 属性定义（不同模型可配置不同窗口大小）。  
  - 对前 `w_size` 个时间步，用**首元素**填充缺失部分（避免窗口大小不足）。  
  - 对 `TranAD` 或 `Attention` 模型，保持 (10, 38) 的二维形状（保留时间步和特征的结构）进行Stack。其他模型（如果窗口大小是5）：窗口被展平为一维张量 w.view(-1)，形状为 (5×38=190,将 5 个时间步的 38 个特征拼接成 190 个特征)再Stack,下图演示了这个过程和区别。
<img width="1457" height="563" alt="image" src="https://github.com/user-attachments/assets/9745e440-7dcc-4482-909c-297d400220e2" />


#### 2. 模型层：多种深度学习模型支持
  目前项目集成的深度学习模型如下，详细的模型介绍请参见文档**时序异常检测模型介绍.pdf**。

| 模型类型       | 核心逻辑                                                                 | 损失函数特点                                                                 |
|----------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|
| Autoencoder（基础） | 最简单的自编码器模型                 | 均方误差（MSE），直接衡量重构误差                                             |
| TranAD         | 基于Transformer的异常检测模型，捕捉长时序依赖，输出双预测结果（动态加权） | MSE，对两个预测结果用动态权重（随训练轮次变化）组合损失                       |
| OmniAnomaly    | 变分自编码器（VAE）变体，引入KL散度正则化                                 | MSE（重构损失）+ β×KL散度（正则化，避免过拟合）                              |
| DTAAD           | 双自编码器模型，两个自编码器相互约束                                      | 两个自编码器的损失组合（带动态权重，随训练轮次调整）                           |
#### 3. 加载模型
  如果加载的是预训练模型，比如上次训练了10轮，那么这次会从11轮开是继续训练模型。

#### 4. 训练与推理流程
设计了包含训练和测试基类，不同模型继承并重写训练测试方法。如下图，基类。
    
<img width="1034" height="396" alt="image" src="https://github.com/user-attachments/assets/8549b5e0-2075-4005-9804-a78eb9ec1b16" /> 
    
TranAD子类继承如下图： 
    
<img width="963" height="125" alt="image" src="https://github.com/user-attachments/assets/3cf7629a-ff35-4efb-be27-f2128ea81cc3" />

    
- **训练模式（training=True）**：  
  - 输入：窗口化的训练数据、模型、优化器（AdamW，带权重衰减防过拟合）、学习率调度器（StepLR，每5轮衰减为0.9倍）。  
  - 过程：**根据模型类型**计算损失（如MSE），通过反向传播更新模型参数，记录损失和学习率。  
  - 输出：本轮平均损失和当前学习率，用于监控训练过程。

- **测试模式（training=False）**：  
  - 输入：窗口化的测试数据、训练好的模型。  
  - 过程：关闭梯度计算，模型输出预测/重构结果，循环计算每个特征的损失（SMD数据集38次）用POT算法计算异常阈值并评估。平均训练集，测试集所有特征的损失进行评估，综合异常标签（只要有一个特征异常则标记为异常）
  - 打印每个特征的评估结果和综合评估结果。

#### 5. 模型保存与加载
- **保存（save_model）**：将模型参数、优化器状态、调度器状态、训练轮次、损失记录保存到 `checkpoints/模型名_数据集名/` 路径，方便中断后继续训练或直接用于测试。  
- **加载（load_model）**：根据模型名动态加载 `src.models` 中的模型类，若存在预训练模型则加载参数，否则初始化新模型（支持 `retrain` 参数控制是否重新训练）。  


#### 6. 异常判定
结合 `src.pot.py` 中的 `objFun` 函数为：  
- 测试阶段计算所有样本的损失（重构/预测误差）。
- 计算完重构误差后，用 POT（Peak Over Threshold，峰值超过阈值）算法确定“正常损失阈值”（基于训练集正常数据的损失分布）。
      SPOT算法是一种用于异常检测的统计方法，基于极值理论（EVT），通过动态调整阈值来检测异常点。
- 损失超过阈值的样本被标记为异常，与真实标签（`labels`）对比计算评估指标（如精确率、召回率，可能在 `src.utils` 中实现）。
#### 7.检测指标
该项目用到的检测指标说明

| 指标名称       | 指标含义                                                                 | 计算逻辑公式（简化）                          | 核心作用                                                                 |
| -------------- | ------------------------------------------------------------------------ | --------------------------------------------- | ------------------------------------------------------------------------ |
| TP | 模型预测为“异常”且实际确实是“异常”的样本数量（真正异常被正确识别）     | $TP = $预测异常 ∩ 实际异常的样本数             | 衡量模型“抓异常”的基础能力，是召回率、F1 等指标的基础                  |
| TN | 模型预测为“正常”且实际确实是“正常”的样本数量（真正正常被正确识别）     | $TN = $预测正常 ∩ 实际正常的样本数             | 衡量模型“认正常”的基础能力，体现对正常样本的辨别精度                    |
| FP | 模型预测为“异常”但实际是“正常”的样本数量（正常样本被误判为异常）       | $FP = $预测异常 ∩ 实际正常的样本数             | 反映“误报”情况，误报越多说明模型对正常样本的干扰越敏感                  |
| FN | 模型预测为“正常”但实际是“异常”的样本数量（异常样本被漏判为正常）       | $FN = $预测正常 ∩ 实际异常的样本数             | 反映“漏检”情况，漏检越多说明模型对异常样本的覆盖能力越差                |
| precision | 预测为“异常”的样本中，真正是“异常”的比例                               | $precision = \frac{TP}{TP + FP}$              | 衡量“预测异常的样本里，有多少真异常”，侧重**减少误报**                  |
| recall| 实际是“异常”的样本中，被模型预测为“异常”的比例                         | $recall = \frac{TP}{TP + FN}$                 | 衡量“真实异常里，有多少被模型找到”，侧重**减少漏检**                    |
| f1| 精确率和召回率的调和平均，平衡“不误报”和“不漏检”的综合表现             | $f1 = \frac{2 \times precision \times recall}{precision + recall}$ | 综合评估模型在“误报”和“漏检”之间的权衡能力，适合整体效果对比           |
| ROC/AUC  | ROC 曲线下的面积（ROC 曲线基于不同阈值下 TPR 和 FPR 绘制）              | 基于所有可能阈值下，TPR（召回率）与 FPR（假正率）的曲线面积计算 | 衡量模型**区分异常与正常样本的能力**，与阈值无关，值越接近 1 区分能力越强 |

